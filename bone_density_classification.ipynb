{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzL4W7Mjhssh"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install opencv-python scikit-learn pandas matplotlib numpy imbalanced-learn\n",
        "!pip install albumentations tqdm timm\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import timm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Enhanced Configuration\n",
        "class Config:\n",
        "    BASE_PATH = \"/content/drive/MyDrive/osteoporosis/Fixed image for training CNN models\"\n",
        "    CLASSES = ['Normal', 'osteophenia', 'osteoporosis']\n",
        "    IMAGE_SIZE = (384, 384)  # Balanced size for performance and accuracy\n",
        "    BATCH_SIZE = 16  # Optimal batch size\n",
        "    NUM_EPOCHS = 100\n",
        "    LEARNING_RATE = 0.001\n",
        "    NUM_CLASSES = 3\n",
        "    EARLY_STOPPING_PATIENCE = 15\n",
        "    TTA_NUM = 10\n",
        "    DROPOUT_RATE = 0.3\n",
        "    WEIGHT_DECAY = 1e-5\n",
        "    NUM_WORKERS = 2\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Advanced Data Augmentation\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(*config.IMAGE_SIZE),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=45, p=0.7),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
        "    A.GaussNoise(var_limit=(10.0, 30.0), p=0.3),\n",
        "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(*config.IMAGE_SIZE),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Dataset Class with Error Handling\n",
        "class BoneDensityDataset(Dataset):\n",
        "    def __init__(self, root_dir, classes, transform=None, tta=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "        self.tta = tta\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(self.classes):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if not os.path.exists(class_dir):\n",
        "                print(f\"Warning: Directory not found - {class_dir}\")\n",
        "                continue\n",
        "\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(class_dir, img_name)\n",
        "                    self.image_paths.append(img_path)\n",
        "                    self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            image = cv2.imread(img_path)\n",
        "            if image is None:\n",
        "                raise ValueError(f\"Could not read image {img_path}\")\n",
        "\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            if self.transform:\n",
        "                if self.tta:\n",
        "                    images = [self.transform(image=image)['image'] for _ in range(config.TTA_NUM)]\n",
        "                    return images, torch.tensor(label, dtype=torch.long)  # Ensure label is long type\n",
        "                else:\n",
        "                    image = self.transform(image=image)['image']\n",
        "                    return image, torch.tensor(label, dtype=torch.long)  # Ensure label is long type\n",
        "            return image, torch.tensor(label, dtype=torch.long)  # Ensure label is long type\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {str(e)}\")\n",
        "            dummy = torch.zeros((3, *config.IMAGE_SIZE), dtype=torch.float32)\n",
        "            return (dummy, torch.tensor(0, dtype=torch.long)) if not self.tta else ([dummy]*config.TTA_NUM, torch.tensor(0, dtype=torch.long))\n",
        "\n",
        "# Initialize datasets\n",
        "print(\"Loading datasets...\")\n",
        "full_dataset = BoneDensityDataset(\n",
        "    root_dir=config.BASE_PATH,\n",
        "    classes=config.CLASSES,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "# Print class distribution\n",
        "print(\"\\nClass Distribution:\")\n",
        "class_counts = np.unique(full_dataset.labels, return_counts=True)\n",
        "for class_idx, count in zip(class_counts[0], class_counts[1]):\n",
        "    print(f\"{config.CLASSES[class_idx]}: {count} images\")\n",
        "\n",
        "# Handle class imbalance with oversampling\n",
        "print(\"\\nBalancing dataset...\")\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "indices = np.arange(len(full_dataset)).reshape(-1, 1)\n",
        "resampled_indices, _ = ros.fit_resample(indices, full_dataset.labels)\n",
        "\n",
        "# Create balanced dataset\n",
        "balanced_dataset = torch.utils.data.Subset(full_dataset, resampled_indices.squeeze())\n",
        "\n",
        "# Stratified split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = next(sss.split(resampled_indices, [full_dataset.labels[i] for i in resampled_indices.squeeze()]))\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(balanced_dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(\n",
        "    BoneDensityDataset(\n",
        "        root_dir=config.BASE_PATH,\n",
        "        classes=config.CLASSES,\n",
        "        transform=val_transform\n",
        "    ),\n",
        "    val_indices\n",
        ")\n",
        "\n",
        "# TTA validation dataset\n",
        "tta_val_dataset = torch.utils.data.Subset(\n",
        "    BoneDensityDataset(\n",
        "        root_dir=config.BASE_PATH,\n",
        "        classes=config.CLASSES,\n",
        "        transform=train_transform,\n",
        "        tta=True\n",
        "    ),\n",
        "    val_indices\n",
        ")\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "tta_val_loader = DataLoader(\n",
        "    tta_val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Enhanced Model Architecture with EfficientNet-B3\n",
        "class BoneDensityModel(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super().__init__()\n",
        "        # Using EfficientNet-B3 with proper feature extraction\n",
        "        self.backbone = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "\n",
        "        # Freeze first 50% of the model\n",
        "        num_layers = len(list(self.backbone.parameters()))\n",
        "        for i, (name, param) in enumerate(self.backbone.named_parameters()):\n",
        "            if i < num_layers * 0.5:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Get number of features from the backbone\n",
        "        num_features = self.backbone.classifier.in_features\n",
        "\n",
        "        # Replace classifier with custom head\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=config.DROPOUT_RATE),\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.SiLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(p=config.DROPOUT_RATE/2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BoneDensityModel(num_classes=config.NUM_CLASSES).to(device)\n",
        "\n",
        "# Label Smoothing Cross Entropy Loss\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        log_probs = torch.nn.functional.log_softmax(x, dim=-1)\n",
        "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -log_probs.mean(dim=-1)\n",
        "        loss = (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = torch.tensor([\n",
        "    1.0 / (class_counts[1][0] + 1e-6),\n",
        "    1.0 / (class_counts[1][1] + 1e-6),\n",
        "    1.0 / (class_counts[1][2] + 1e-6)\n",
        "], device=device, dtype=torch.float32)  # Ensure weights are float32\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "\n",
        "# Optimizer with weight decay\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config.LEARNING_RATE,\n",
        "    weight_decay=config.WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = CosineAnnealingWarmRestarts(\n",
        "    optimizer,\n",
        "    T_0=10,\n",
        "    T_mult=1,\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "# Loss functions\n",
        "criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "focal_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, loader, optimizer, criterion, focal_criterion, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
        "        images = images.to(device, dtype=torch.float32)  # Ensure input is float32\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = 0.7 * criterion(outputs, labels) + 0.3 * focal_criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    scheduler.step()\n",
        "    return running_loss / len(loader), correct / total\n",
        "\n",
        "# Validation function\n",
        "def validate(model, loader, criterion, focal_criterion, tta_loader=None):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=\"Validating\"):\n",
        "            images = images.to(device, dtype=torch.float32)  # Ensure input is float32\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = 0.7 * criterion(outputs, labels) + 0.3 * focal_criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_loss = running_loss / len(loader)\n",
        "    val_acc = correct / total\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    # TTA validation\n",
        "    tta_acc = None\n",
        "    tta_f1 = None\n",
        "    if tta_loader:\n",
        "        tta_correct = 0\n",
        "        tta_total = 0\n",
        "        tta_preds = []\n",
        "        tta_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, label in tqdm(tta_loader, desc=\"TTA Validating\"):\n",
        "                label = label.to(device)\n",
        "                outputs = []\n",
        "\n",
        "                for img in images[0]:\n",
        "                    img = img.unsqueeze(0).to(device, dtype=torch.float32)  # Ensure input is float32\n",
        "                    with autocast():\n",
        "                        output = model(img)\n",
        "                    outputs.append(output)\n",
        "\n",
        "                avg_output = torch.mean(torch.stack(outputs), dim=0)\n",
        "                _, predicted = avg_output.max(1)\n",
        "\n",
        "                tta_total += 1\n",
        "                tta_correct += predicted.eq(label).sum().item()\n",
        "                tta_preds.append(predicted.cpu().numpy()[0])\n",
        "                tta_labels.append(label.cpu().numpy()[0])\n",
        "\n",
        "        tta_acc = tta_correct / tta_total\n",
        "        tta_f1 = f1_score(tta_labels, tta_preds, average='weighted')\n",
        "\n",
        "    return val_loss, val_acc, f1, tta_acc, tta_f1\n",
        "\n",
        "# Training loop\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "scaler = GradScaler()\n",
        "\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': [],\n",
        "    'val_f1': [],\n",
        "    'tta_acc': [],\n",
        "    'tta_f1': []\n",
        "}\n",
        "\n",
        "for epoch in range(config.NUM_EPOCHS):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, focal_criterion, scaler)\n",
        "    val_loss, val_acc, val_f1, tta_acc, tta_f1 = validate(model, val_loader, criterion, focal_criterion, tta_val_loader)\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_f1'].append(val_f1)\n",
        "    if tta_acc:\n",
        "        history['tta_acc'].append(tta_acc)\n",
        "        history['tta_f1'].append(tta_f1)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{config.NUM_EPOCHS}:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2%}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2%} | Val F1: {val_f1:.4f}\")\n",
        "    if tta_acc:\n",
        "        print(f\"TTA Val Acc: {tta_acc:.2%} | TTA F1: {tta_f1:.4f}\")\n",
        "\n",
        "    current_acc = tta_acc if tta_acc else val_acc\n",
        "    if current_acc > best_val_acc:\n",
        "        best_val_acc = current_acc\n",
        "        patience_counter = 0\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': val_loss,\n",
        "            'accuracy': best_val_acc\n",
        "        }, '/content/best_model.pth')\n",
        "        print(\"Saved new best model\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['train_acc'], label='Train Acc')\n",
        "plt.plot(history['val_acc'], label='Val Acc')\n",
        "if 'tta_acc' in history:\n",
        "    plt.plot(history['tta_acc'], label='TTA Val Acc')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Load best model\n",
        "checkpoint = torch.load('/content/best_model.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, loader, tta_loader=None, set_name=\"Validation\"):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=f\"Evaluating {set_name}\"):\n",
        "            images = images.to(device, dtype=torch.float32)  # Ensure input is float32\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    print(f\"\\nStandard {set_name} Set Evaluation:\")\n",
        "    print(f\"Accuracy: {acc:.2%}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=config.CLASSES, zero_division=0, digits=4))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(all_labels, all_preds))\n",
        "\n",
        "    if tta_loader:\n",
        "        tta_preds = []\n",
        "        tta_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, label in tqdm(tta_loader, desc=f\"TTA {set_name}\"):\n",
        "                label = label.to(device)\n",
        "                outputs = []\n",
        "\n",
        "                for img in images[0]:\n",
        "                    img = img.unsqueeze(0).to(device, dtype=torch.float32)  # Ensure input is float32\n",
        "                    with autocast():\n",
        "                        output = model(img)\n",
        "                    outputs.append(output)\n",
        "\n",
        "                avg_output = torch.mean(torch.stack(outputs), dim=0)\n",
        "                _, predicted = avg_output.max(1)\n",
        "                tta_preds.append(predicted.cpu().numpy()[0])\n",
        "                tta_labels.append(label.cpu().numpy()[0])\n",
        "\n",
        "        tta_acc = accuracy_score(tta_labels, tta_preds)\n",
        "        tta_f1 = f1_score(tta_labels, tta_preds, average='weighted')\n",
        "\n",
        "        print(f\"\\nTTA {set_name} Set Evaluation:\")\n",
        "        print(f\"Accuracy: {tta_acc:.2%}\")\n",
        "        print(f\"F1 Score: {tta_f1:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(tta_labels, tta_preds, target_names=config.CLASSES, zero_division=0, digits=4))\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(confusion_matrix(tta_labels, tta_preds))\n",
        "\n",
        "        return tta_acc\n",
        "    return acc\n",
        "\n",
        "print(\"\\n=== Final Evaluation ===\")\n",
        "train_acc = evaluate_model(model, train_loader, set_name=\"Training\")\n",
        "val_acc = evaluate_model(model, val_loader, tta_val_loader, \"Validation\")\n",
        "\n",
        "print(\"\\n=== PROCESS COMPLETED SUCCESSFULLY ===\")\n",
        "print(f\"Final Validation Accuracy: {val_acc:.2%}\")"
      ]
    }
  ]
}